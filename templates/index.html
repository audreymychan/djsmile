<!DOCTYPE html>
<html lang="en" dir="ltr">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Dad Jokes for Smiles</title>
  <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
  <link rel="stylesheet" type="text/css" href="{{ url_for('static', filename='styles/style.css') }}">
  <link rel="stylesheet" type="text/css" href="{{ url_for('static', filename='fonts/font.css') }}">
  <link href="https://fonts.googleapis.com/css?family=Merriweather|Montserrat&display=swap" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css?family=Cardo:400,700|Oswald" rel="stylesheet">
  <link rel="icon" type="image/png" sizes="32x32" href="{{ url_for('static', filename='images/favicon-32x32.png') }}">
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-141611830-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }
    gtag('js', new Date());

    gtag('config', 'UA-141611830-1');
  </script>

</head>

<body>

  <!-- navbar -->
  <nav class="navbar fixed-top navbar-dark navbar-translucent">
    <a class="navbar-brand" href="">
      <img src="/static/images/dad.png" width="35" height="35" class="d-inline-block align-top" alt="logo">
      Dad Jokes for Smiles
    </a>
  </nav>

  <!-- carousel -->
  <section class="carousel slide" data-ride="carousel">
    <div class="carousel-inner d-flex h-100">
      <div class="carousel-item active">
        <img class="img-fluid" src="/static/images/smile_bg_1.png" alt="First slide">
        <a class="bottom-right" href="http://www.freepik.com">Image designed by Katemangostar / Freepik</a>
      </div>
      <div class="carousel-item">
        <img class="img-fluid" src="/static/images/smile_bg_2.png" alt="Second slide">
        <a class="bottom-right" href="http://www.freepik.com">Image designed by Bearfotos / Freepik</a>
      </div>
      <div class="carousel-item">
        <img class="img-fluid" src="/static/images/smile_bg_3.png" alt="Third slide">
        <a class="bottom-right" href="http://www.freepik.com">Imaged designed by Freepik</a>
      </div>
      <!-- carousel content -->
      <div class="carousel-content container">
        <div class="row">
          <div class="col-sm-12">
            <div>
              <h1 class="boxed">Dad jokes to put a smile on your face</h1>
              <h2 class="boxed">Smile detection algorithm using deep learning convolutional neural networks</h2>
              <br></br>
              <a class="btn btn-warning" href="#livefeed">Try it out ▼</a>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- live feed and joke section -->
  <section id="livefeed">
    <div class="row">
      <div class="col-7 video">
        <img class="rounded border" src="{{ url_for('video_feed') }}" alt="live video feed" />
        <a class="btn btn-warning mt-4" href="#about">LEARN MORE ▼</a>
      </div>
      <div class="col-5 joke">
        <div class="row">
          <div class="col">
            <img class="ml-4" src="/static/images/dad_black.png" alt="logo">
          </div>
        </div>
        <div class="row">
          <div class="col">
            <p class="bubble">{{ joke }}</p>
          </div>
        </div>
        <div class="row">
          <div class="col center">

            <form method="POST" action="/">
              <input type="submit" class="btn btn-warning btn-sm rounded-circle float-right" name="next" value="↻">
            </form>

            {% if scroll %}
            <script>
              document.getElementById('{{ scroll }}').scrollIntoView();
              // or
              document.location.hash = '#' + '{{ scroll }}';
            </script>
            {% endif %}

          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- about section -->
  <section id="about">
    <div class="container">
      <h4>Learn the Process</h4>
      <hr />
      <h5>Smile detection applications are countless, from activating a camera shutter automatically, enhancing human-robot interaction, to being incorporated into assistive communication devices for people with disabilities.</h5>
      <h5>Using deep learning convolutional neural network algorithms, an accuracy of 89% was achieved!</h5>
      <hr />
      <div class="row">
        <div class="col-2">
          <img src="/static/images/scraper.png" alt="scraper">
        </div>
        <div class="col-9">
          <h6>Web Scraping</h6>
          <p>Total of 8,600 images were scraped from Getty Images based on searches for "smile" and "no smile".</p>
          <img src="/static/images/smile_example_1.jpg" width="130" alt="smile_example_1">
          <img src="/static/images/smile_example_2.jpg" width="130" alt="smile_example_2">
          <img src="/static/images/no_smile_example_1.jpg" width="130" alt="no_smile_example_1">
          <img src="/static/images/no_smile_example_2.jpg" width="130" alt="no_smile_example_2">
          <p><b>Tools:</b> requests, BeautifulSoup</p>
        </div>
      </div>
      <div class="row">
        <div class="col-2">
          <img src="/static/images/edit.png" alt="edit">
        </div>
        <div class="col-9">
          <h6>Image Pre-Processing</h6>
          <p>Images collected were:</p>
          <ul>
            <li>cropped with a bounding box around faces detected</li>
            <li>converted to grayscale</li>
            <li>resized down to 100 x 100 px</li>
            <li>convert into an array</li>
            <li>normalized</li>
          </ul>
          <p>Image dataset was split into a training set and a test set (for model evaluation).</p>
          <p>Random transformations and normalization operations (i.e. adjusting for rotation and lighting) were
            configured on the training set to create more variation for the model to learn.</p>
          <img src="/static/images/grey_crop_smile_1.jpg" width="130" alt="grey_crop_smile_1">
          <img src="/static/images/grey_crop_smile_2.jpg" width="130" alt="grey_crop_smile_2">
          <img src="/static/images/grey_crop_no_smile_1.jpg" width="130" alt="grey_crop_no_smile_1">
          <img src="/static/images/grey_crop_no_smile_2.jpg" width="130" alt="grey_crop_no_smile_2">
          <p><b>Image to array example</b> (each pixel ranging from 0 to 255):</p>
          <img src="/static/images/img_to_array.gif" width="150" alt="img_to_array">
          <p><b>Tools:</b> PIL - Image, face_recognition, tensorflow.keras - array_to_img, img_to_array, ImageDataGenerator, to_categorical, sklearn - MinMaxScaler, LabelEncoder, train_test_split</p>
        </div>
      </div>
      <div class="row">
        <div class="col-2">
          <img src="/static/images/training.png" alt="training">
        </div>
        <div class="col-9">
          <h6>Training the Model - Convolutional Neural Network (CNN)</h6>
          <ol>
            <li>
              <p><b>Convolution Steps:</b> Aims to extract features, using small squares of input data.</p>
              <p>Example of a convulated feature map from a 5 x 5 image and the 3 x 3 (filter) matrix:</p>
              <img src="/static/images/convolution.gif" width="300" alt="convolution">
              <p>Different filter matrices can detect different features from an image (i.e. edges, curves, etc.).</p>
              <p>Example of two different filter matrices (outline red and green) sliding over an image to extract different features from an image:</p>
              <img src="/static/images/convolution_2.gif" width="460" alt="convolution_2">
            </li>
            <li>
              <p><b>RELU (Rectified Linear Unit) Steps:</b> Replaces all negative pixel values in the convulated feature map with zeros. Values of a feature map can range from -infinity to infinity. Without any bounds, "neurons" don't know when to
                "fire" or not. RELU helps determine when "neurons" should be activated.</p>
              <img src="/static/images/relu.png" width="460" alt="relu">
            </li>
            <li>
              <p><b>Pooling Steps:</b> Reduces dimensionality of a feature map.</p>
              <p>Example of a Max Pooling operation:</p>
              <img src="/static/images/max_pooling.png" width="350" alt="pooling">
            </li>
            <li>
              <p><b>Fully Connected Layers:</b> The output from the convolutional and pooling layers represent high-level features of the input image. The purpose of the Fully Connected layer is to use these features for classifying the input
                image
                into various classes (in our case, smile versus no smile) based on the training image dataset. </p>
              <img src="/static/images/fully_connected.png" width="350" alt="fully_connected">
            </li>
            <li>
              <p><b>Training with Backpropagation:</b> Convolution + Pooling layers act as Feature Extractors from the input image while Fully Connected layer acts as a classifier.</p>
              <p>Convolution neural networks can have any number of convolution, pooling, and fully connected layers and nodes.</p>
              <p>Example of a convolution neural network for predicting a boat class:</p>
              <img src="/static/images/convnet_training.png" width="700" alt="convnet_training">
              <p>The training process consists of first initializing all filters and weights with random values. Then an image is put through the network to calculate its output probabilities for each class, along with the error. Based on the error,
                we
                backpropagate through the network to update the weights to minimize errors. This process is repeated for all images in the training dataset, with the goal to minimize a loss function (i.e. accuracy).</p>
              <p><b>Tools:</b> tensorflow.keras - Sequential, Input, Conv2D, MaxPooling2D, Dropout, Dense, Flatten, EarlyStopping</p>
            </li>
          </ol>
        </div>
      </div>

      <div class="row">
        <div class="col-2">
          <img src="/static/images/save.png" alt="training">
        </div>
        <div class="col-9">
          <h6>Saving the Model</h6>
          <p>The CNN model and weights learned can now be saved and used to predict smile versus no smile on any new image.</p>
          <p><b>Tools:</b> sklearn - joblib, tensorflow.keras - save, load_model</p>
        </div>
      </div>
      <div class="row">
        <a class="btn btn-warning mx-auto mt-4" href="#livefeed">Back ▲</a>
      </div>
    </div>

  </section>

  <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js" integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q" crossorigin="anonymous"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js" integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl" crossorigin="anonymous"></script>

</body>

<!-- ?</html> -->
